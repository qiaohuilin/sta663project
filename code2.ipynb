{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import sklearn.preprocessing\n",
    "import sklearn.neural_network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "import h5py\n",
    "warnings.resetwarnings()\n",
    "warnings.simplefilter(action='ignore', category=ImportWarning)\n",
    "warnings.simplefilter(action='ignore', category=RuntimeWarning)\n",
    "warnings.simplefilter(action='ignore', category=DeprecationWarning)\n",
    "warnings.simplefilter(action='ignore', category=ResourceWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_data, train_labels), (test_data, test_labels) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 28, 28)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reshape and standardize\n",
    "x=train_data\n",
    "y=test_data\n",
    "xres=x.reshape(60000,-1)\n",
    "yres=y.reshape(10000,-1)\n",
    "xsd=sklearn.preprocessing.normalize(xres,axis=0)\n",
    "ysd=sklearn.preprocessing.normalize(yres,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "N=60000\n",
    "M=100\n",
    "alpha=0.01 #step size,        or 0.02, 0.1\n",
    "D=28*28 #dimension of x_i 28*28\n",
    "J=2   #dimension of z         or 5,10,20\n",
    "\n",
    "#initialize \\phi\n",
    "u=np.zeros([10000,J])  #assume 10000 iterations, can kick out empty rows if converge early\n",
    "sig2=np.zeros([10000,J])\n",
    "u[0,]=np.random.normal(0,0.01,J)\n",
    "sig2[0,]=np.random.normal(0,0.01,J)**2\n",
    "#initialize \\theta\n",
    "uprime=np.zeros([10000,D])  #assume 10000 iterations, can kick out empty rows if converge early\n",
    "sig2prime=np.zeros([10000,D])\n",
    "uprime[0,]=np.random.normal(0,0.01,D)\n",
    "sig2prime[0,]=np.random.normal(0,0.01,D)**2\n",
    "\n",
    "#set seed\n",
    "np.random.seed(123)\n",
    "L=np.zeros([10000,M])        # we want to keep the track of lower bound each iter to replicate Fig2\n",
    "LM=np.zeros(10000)           #LM with batch size M, for 10000 iter\n",
    "#maybe we can get rid of Ls if the code is slow and only keep the SGVB update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "while True:\n",
    "    t=0\n",
    "    xm=xsd[np.random.randint(0,N-1,M),]\n",
    "    u_temp=np.random.normal(0,0.01,[M,J])\n",
    "    sig2_temp=np.random.normal(0,0.01,[M,J])**2\n",
    "    uprime_temp=np.random.normal(0,0.01,[M,D])\n",
    "    sig2prime_temp=np.random.normal(0,0.01,[M,D])**2\n",
    "    \n",
    "    for i in range(M):\n",
    "        # MLP use x_i to get \\phi_t(i) u_temp[i,] and sig2_temp[i,], which is same dimension as z (J)\n",
    "        eps=np.random.multivariate_normal(np.zeros(J),np.eye(2))\n",
    "        z=u_temp[i,]+sig2_temp[i,]*eps\n",
    "        # MLP use z_i to get \\theta_t(i) uprime_temp[i,] and sig2prime_temp[i,], which is same dimension as x(D)\n",
    "        L[t,i]=1/2 * (J+sum(np.log(sig2_temp[i,]))-sum(u_temp[i,]**2)-sum(sig2_temp[i,])) - 1/2* (D*np.log(2*np.pi)+sum(np.log(sig2prime_temp[i,])))- 1/2 * sum((xm[i,]-uprime_temp[i,])**2*1/sig2prime_temp[i,])\n",
    "        LM[t]=N/M*sum(L[t,])\n",
    "        \n",
    "    for j in range(J):\n",
    "        u[t+1,j]=u[t,j]- alpha*N/M*(-sum(u_temp[:,j]))    # to confirm it's minus?? gradient descent. the written part says ascent\n",
    "        sig2[t+1,j]=sig2[t,j] -alpha*N/M*(1/2)*sum(1/sig2_temp[:,j]-1)\n",
    "    \n",
    "    for d in range(D):\n",
    "        uprime[t+1,d]=uprime[t,d]-alpha*N/M*sum(1/sig2prime_temp[:,d]*(xm[:,d]-uprime_temp[:,d]))\n",
    "        sig2prime[t+1,d]=sig2prime[t,d]-alpha*N/M*sum(1/2 * (1/(sig2prime_temp[:,d])**2*(xm[:,d]-uprime_temp[:,d])**2-1/(sig2prime_temp[:,d])))\n",
    "        \n",
    "    if (np.norm(u[t+1,]-u[t,])<1e-4) & (np.norm(sig2[t+1,]-sig2[t,])<1e-4) & (np.norm(uprime[t+1,]-uprime[t,])<1e-4) & (np.norm(sig2prime[t+1,]-sig2prime[t,])<1e-4):\n",
    "        break\n",
    "    \n",
    "    t=t+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "t=0\n",
    "xm=xsd[np.random.randint(0,N-1,M),]\n",
    "u_temp=np.random.normal(0,0.01,[M,J])\n",
    "sig2_temp=np.random.normal(0,0.01,[M,J])**2\n",
    "uprime_temp=np.random.normal(0,0.01,[M,D])\n",
    "sig2prime_temp=np.random.normal(0,0.01,[M,D])**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-35515.32383858882"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i=0\n",
    "j=1\n",
    "d=1\n",
    "1/2 * (J+sum(np.log(sig2_temp[i,]))-sum(u_temp[i,]**2)-sum(sig2_temp[i,])) - 1/2* (D*np.log(2*np.pi)+sum(np.log(sig2prime_temp[i,])))- 1/2 * sum((xm[i,]-uprime_temp[i,])**2*1/sig2prime_temp[i,])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.6299508546444965"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alpha*N/M*(-sum(u_temp[:,j]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "128851827.5106982"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alpha*N/M*(1/2)*sum(1/sig2_temp[:,j]-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1816474.4503423912"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alpha*N/M*sum(1/sig2prime_temp[:,d]*(xm[:,d]-uprime_temp[:,d]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "239025213526.04416"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alpha*N/M*sum(1/2 * (1/(sig2prime_temp[:,d])**2*(xm[:,d]-uprime_temp[:,d])**2-1/(sig2prime_temp[:,d])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp=sklearn.neural_network.MLPRegressor(hidden_layer_sizes=(100, ), \n",
    "                                    activation='tanh', solver='adam', alpha=0.0001, \n",
    "                                    batch_size='auto', learning_rate='constant', learning_rate_init=0.001,\n",
    "                                    power_t=0.5, max_iter=200, shuffle=True, random_state=None, tol=0.0001, \n",
    "                                    verbose=False, warm_start=False, momentum=0.9, nesterovs_momentum=True, \n",
    "                                    early_stopping=False, validation_fraction=0.1, beta_1=0.9, beta_2=0.999, \n",
    "                                    epsilon=1e-08)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 2)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zprior=np.random.multivariate_normal(np.zeros(2),np.eye(2),100)\n",
    "zprior.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-3.92644069e-04,  3.31058456e-03,  2.92139819e-03, ...,\n",
       "         6.73071449e-03, -7.31814525e-03,  8.02606636e-04],\n",
       "       [ 6.44762505e-06, -2.99852943e-04,  2.94799406e-05, ...,\n",
       "        -2.22464269e-06, -2.38747187e-06,  3.77498835e-03],\n",
       "       [ 5.90300585e-03,  4.91464747e-04, -1.23029112e-03, ...,\n",
       "         3.14705344e-04, -5.68276107e-03, -1.78950455e-06],\n",
       "       ...,\n",
       "       [-5.88338997e-04,  7.48426106e-07, -5.89381503e-03, ...,\n",
       "        -6.53735586e-03,  1.56225340e-04,  2.56666943e-04],\n",
       "       [ 5.22728741e-05, -1.88300452e-03, -1.07034200e-04, ...,\n",
       "         6.64640935e-05,  3.59498339e-04,  9.20870085e-04],\n",
       "       [-4.69224700e-04, -3.68115900e-03,  1.97417915e-04, ...,\n",
       "        -1.64344766e-03, -3.80720063e-03, -2.48725164e-06]])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "warnings.simplefilter(action='ignore')\n",
    "mlp.fit(xm,zprior)\n",
    "mlp.score(xm, zprior)\n",
    "#res.coefs_[0].shape\n",
    "mlp.coefs_[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
